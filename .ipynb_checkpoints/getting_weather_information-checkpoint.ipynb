{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pymysql\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "\n",
    "def main():\n",
    "    url1 = # NAVER SEARCH URL EX) \"\"\"https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=%EB%B6%80%EC%82%B0+%EA%B0%95%EC%84%9C%EA%B5%AC+%EA%B0%95%EB%8F%99%EB%8F%99+%EB%82%A0%EC%94%A8\"\"\"\n",
    "    url2 = # NAVER SEARCH URL2\n",
    "    url3 = # NAVER SEARCH URL3\n",
    "    url_dict = {}\n",
    "    url_dict[0] = url1\n",
    "    url_dict[1] = url2\n",
    "    url_dict[2] = url3\n",
    "    table_name = # [DB table name1 Ex)\"Gangnam\", DB table name2, DB table name3]\n",
    "    with open('login_information.txt', 'rt', encoding='utf8') as f:\n",
    "        info_list = f.readlines()\n",
    "        host = info_list[0].strip().split(\"=\")[1]\n",
    "        port = info_list[1].strip().split(\"=\")[1]\n",
    "        user = info_list[2].strip().split(\"=\")[1]\n",
    "        passwd = info_list[3].strip().split(\"=\")[1]\n",
    "        db = info_list[4].strip().split(\"=\")[1]\n",
    "        charset = info_list[5].strip().split(\"=\")[1]\n",
    "        db = pymysql.connect(host=host, port=int(port), user=user, passwd=passwd, db=db, charset=charset)\n",
    "        cursor = db.cursor()\n",
    "        for i in range(len(url_dict)):\n",
    "            url = url_dict[i]\n",
    "            html = requests.get(url)\n",
    "            plain_text = html.text\n",
    "            soup = bs(plain_text, 'lxml')\n",
    "            area = soup.find('span', {'class': 'btn_select'}).find('em')\n",
    "            if area is not None:\n",
    "                area = area.text\n",
    "            else:\n",
    "                print(\"Area is none!\")\n",
    "                area = \"\"\n",
    "            current_temp = soup.find('span', {'class': 'todaytemp'})\n",
    "            if current_temp is not None:\n",
    "                current_temp = current_temp.text\n",
    "            else:\n",
    "                print(\"Current temp is none!\")\n",
    "                current_temp = -1\n",
    "            min_temp = soup.find('span', {'class': 'min'})\n",
    "            if min_temp is not None:\n",
    "                min_temp = min_temp.text[:-1]\n",
    "            else:\n",
    "                print(\"Min temp is none!\")\n",
    "                min_temp = -1\n",
    "            max_temp = soup.find('span', {'class': 'max'})\n",
    "            if max_temp is not None:\n",
    "                max_temp = max_temp.text[:-1]\n",
    "            else:\n",
    "                print(\"Max temp is none!\")\n",
    "                max_temp = -1\n",
    "            sensible_temp = soup.find('span', {'class': 'sensible'}).find('em')\n",
    "            if sensible_temp is not None:\n",
    "                sensible_temp = sensible_temp.text[:-1]\n",
    "            else:\n",
    "                print(\"Sensible temp is none!\")\n",
    "                sensible_temp = -1\n",
    "            weather = soup.find('p', {'class': 'cast_txt'})\n",
    "            if weather is not None:\n",
    "                weather = weather.text.split(',')[0]\n",
    "            else:\n",
    "                print(\"Weather is none!\")\n",
    "                weather = \"\"\n",
    "            uv_num, uv_non_num_content = -1, None\n",
    "            rainfall_amount = -1\n",
    "            uv_num = soup.find('span', {'class': 'indicator'}).find('span', {'class': \"num\"})\n",
    "            rainfall_html = soup.find('span', {'class': 'rainfall'})\n",
    "            if uv_num is not None:\n",
    "                uv_num = uv_num.text\n",
    "                uv_content = soup.find('span', {'class': 'indicator'}).find('span').text\n",
    "                uv_non_num_content_point = uv_content.find(uv_num)+len(uv_num)\n",
    "                uv_non_num_content = uv_content[uv_non_num_content_point: ]\n",
    "            else:\n",
    "                print(\"UV_num is none!\")\n",
    "                uv_num, uv_non_num_content = -1, \"null\"\n",
    "            if rainfall_html is not None:\n",
    "                rainfall_text = rainfall_html.text\n",
    "                rainfall_amount = rainfall_text.split()[2].split(\"mm\")[0]\n",
    "            else:\n",
    "                print(\"Rainfall_html is none!\")\n",
    "                rainfall_amount = -1\n",
    "            fine_dust = \"null\"\n",
    "            fine_dust_num = -1\n",
    "            ultra_fine_dust = \"null\"\n",
    "            ultra_fine_dust_num = -1\n",
    "            ozone = \"null\"\n",
    "            ozone_num = -1\n",
    "            dust_list = []\n",
    "            ozone_text = \"\"\n",
    "            for ele in soup.find_all('dd'):\n",
    "                if \"㎍/㎥\" in ele.text:\n",
    "                    dust_list.append(ele.text)\n",
    "                elif \"ppm\" in ele.text:\n",
    "                    ozone_text = ele.text\n",
    "            if dust_list[0].split(\"㎍/㎥\")[0] is not 'null':\n",
    "                fine_dust = dust_list[0].split(\"㎍/㎥\")[1]\n",
    "                fine_dust_num = dust_list[0].split(\"㎍/㎥\")[0]\n",
    "            else:\n",
    "                print(\"Fine dust is none!\")\n",
    "            if dust_list[1].split(\"㎍/㎥\")[0] is not 'null':\n",
    "                ultra_fine_dust = dust_list[1].split(\"㎍/㎥\")[1]\n",
    "                ultra_fine_dust_num = dust_list[1].split(\"㎍/㎥\")[0]\n",
    "            else:\n",
    "                print(\"Ultra fine dust is none!\")\n",
    "            if ozone_text.split(\"ppm\")[1] is not '':\n",
    "                ozone = ozone_text.split(\"ppm\")[1]\n",
    "                ozone_num = ozone_text.split(\"ppm\")[0]\n",
    "            else:\n",
    "                print(\"Ozone is none!\")\n",
    "            p_rainfall = soup.find(\"div\", {'class': 'info_list rainfall _tabContent'})\n",
    "            if p_rainfall is not None:\n",
    "                p_rainfall = p_rainfall.text.strip().split()[2][:-1]\n",
    "            else:\n",
    "                print(\"P_rainfall is none!\")\n",
    "                p_rainfall = -1\n",
    "            wind_speed = soup.find(\"div\", {'class': 'info_list wind _tabContent'})\n",
    "            if wind_speed is not None:\n",
    "                wind_speed = wind_speed.text.strip().split()[2][:-3]\n",
    "            else:\n",
    "                print(\"Wind speed is none!\")\n",
    "                wind_speed = -1\n",
    "            humidity = soup.find(\"div\", {'class': 'info_list humidity _tabContent'})\n",
    "            if humidity is not None:\n",
    "                humidity = humidity.text.strip().split()[2][:-1]\n",
    "            else:\n",
    "                print(\"Humidity is none!\")\n",
    "                humidity = -1\n",
    "            try:\n",
    "                float(current_temp)\n",
    "            except Exception:\n",
    "                print(area, \"current temp..\", current_temp)\n",
    "                current_temp = -1.0\n",
    "            try:\n",
    "                float(min_temp)\n",
    "            except Exception:\n",
    "                print(area, \"min_temp..\", min_temp)\n",
    "                min_temp = -1.0\n",
    "            try:\n",
    "                float(max_temp)\n",
    "            except Exception:\n",
    "                print(area, \"max_temp..\", max_temp)\n",
    "                max_temp = -1.0\n",
    "            try:\n",
    "                float(sensible_temp)\n",
    "            except Exception:\n",
    "                print(area, \"sensible_temp..\", sensible_temp)\n",
    "                sensible_temp = -1.0\n",
    "            try:\n",
    "                float(uv_num)\n",
    "            except Exception:\n",
    "                print(area, \"uv_num..\", uv_num)\n",
    "                uv_num = -1.0\n",
    "            try:\n",
    "                float(rainfall_amount)\n",
    "            except Exception:\n",
    "                print(area, \"rainfall_amount..\", rainfall_amount)\n",
    "                rainfall_amount = -1.0\n",
    "            try:\n",
    "                float(fine_dust_num)\n",
    "            except Exception:\n",
    "                print(area, \"fine_dust_num..\", fine_dust_num)\n",
    "                fine_dust_num = -1.0\n",
    "            try:\n",
    "                float(ultra_fine_dust_num)\n",
    "            except Exception:\n",
    "                print(area, \"ultra_fine_dust_num..\", ultra_fine_dust_num)\n",
    "                ultra_fine_dust_num = -1.0\n",
    "            try:\n",
    "                float(ozone_num)\n",
    "            except Exception:\n",
    "                print(area, \"ozone_num..\", ozone_num)\n",
    "                ozone_num = -1.0\n",
    "            try:\n",
    "                float(p_rainfall)\n",
    "            except Exception:\n",
    "                print(area, \"p_rainfall..\", p_rainfall)\n",
    "                p_rainfall = -1.0\n",
    "            try:\n",
    "                float(wind_speed)\n",
    "            except Exception:\n",
    "                print(area, \"wind_speed..\", wind_speed)\n",
    "                wind_speed = -1.0\n",
    "            try:\n",
    "                float(humidity)\n",
    "            except Exception:\n",
    "                print(area, \"humidity..\", humidity)\n",
    "                humidity = -1.0\n",
    "            sql = \"\"\"\n",
    "                INSERT INTO {18}\n",
    "                (m_date, area, current_temp, min_temp, max_temp, sensible_temp, weather, uv_num, uv_non_num_content,\n",
    "                rainfall_amount, find_dust_num, find_dust, ultra_find_dust_num, ultra_find_dust, \n",
    "                ozone_num, ozone, p_rainfall, wind_speed, humidity)\n",
    "                VALUES(now(), \"{0}\", {1}, {2}, {3}, {4}, \"{5}\", {6}, \"{7}\", {8}, {9}, \"{10}\", {11}, \"{12}\", {13}, \"{14}\", {15}, {16}, {17});\n",
    "                  \"\"\".format(area, float(current_temp), float(min_temp), float(max_temp), float(sensible_temp), weather, float(uv_num), uv_non_num_content,\n",
    "                float(rainfall_amount), float(fine_dust_num), fine_dust, float(ultra_fine_dust_num), ultra_fine_dust, \n",
    "                float(ozone_num), ozone, float(p_rainfall), float(wind_speed), float(humidity), table_name[i])\n",
    "            cursor.execute(sql)\n",
    "        db.commit()\n",
    "        db.close()\n",
    "        print(\"done\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    scheduler = BackgroundScheduler()\n",
    "    scheduler.add_job(main, 'interval', minutes=15, start_date=\"2019-09-22 15:15:00\")\n",
    "    scheduler.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rainfall_amount information of 서울특별시 강남구 역삼동 is none.\n",
      "{'current_temp': '1', 'min_temp': '-6', 'max_temp': '5', 'sensible_temp': '0.0', 'weather': '흐림', 'rainfall_amount': None, 'p_rainfall': '30', 'wind_speed': '1', 'humidity': '56', 'uv_num': '2', 'uv_non_num_content': '좋음', 'fine_dust': '보통', 'fine_dust_num': '44', 'ultra_fine_dust': '보통', 'ultra_fine_dust_num': '30', 'ozone': '좋음', 'ozone_num': '0.002'}\n",
      "rainfall_amount information of 서울특별시 서초구 방배동 is none.\n",
      "{'current_temp': '-3', 'min_temp': '-6', 'max_temp': '5', 'sensible_temp': '-4.5', 'weather': '구름많음', 'rainfall_amount': None, 'p_rainfall': '30', 'wind_speed': '0', 'humidity': '64', 'uv_num': '2', 'uv_non_num_content': '좋음', 'fine_dust': '나쁨', 'fine_dust_num': '82', 'ultra_fine_dust': '나쁨', 'ultra_fine_dust_num': '41', 'ozone': '좋음', 'ozone_num': '0.002'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "class WeatherInformationCralwer:\n",
    "    def __init__(self):\n",
    "        self._url_dict = {}\n",
    "        self._soup_inst_dict = {}\n",
    "        \n",
    "        \n",
    "    def _set_url_dict(self, url_info):\n",
    "        for url in url_info:\n",
    "            key = url.strip().split(\"@\")[0]\n",
    "            value = url.strip().split(\"@\")[1]\n",
    "            if len(value) != 0:\n",
    "                self._url_dict[key] = value\n",
    "                \n",
    "                \n",
    "    def _set__soup_inst_dict(self):\n",
    "        self._soup_inst_dict[\"current_temp\"] = \"global current_temp; current_temp = None; \" \\\n",
    "                                               \"current_temp = soup.find('span', {'class': 'todaytemp'}).text\"\n",
    "        self._soup_inst_dict[\"min_temp\"] = \"global min_temp; min_temp = None; \" \\\n",
    "                                           \"min_temp = soup.find('span', {'class': 'min'}).text[:-1]\"\n",
    "        self._soup_inst_dict[\"max_temp\"] = \"global max_temp; max_temp = None; \" \\\n",
    "                                           \"max_temp = soup.find('span', {'class': 'max'}).text[:-1]\"\n",
    "        self._soup_inst_dict[\"sensible_temp\"] = \"global sensible_temp; sensible_temp = None; \" \\\n",
    "                                                \"sensible_temp = soup.find('span', {'class': 'sensible'})\" \\\n",
    "                                                \".find('em').text[:-1]\"\n",
    "        self._soup_inst_dict[\"weather\"] = \"global weather; weather = None; \" \\\n",
    "                                          \"weather = soup.find('p', {'class': 'cast_txt'}).text.split(',')[0]\"\n",
    "        self._soup_inst_dict[\"rainfall_amount\"] = \"global rainfall_amount; rainfall_amount = None; \" \\\n",
    "                                   \"rainfall_amount = soup.find('span', \" \\\n",
    "                                   \"{'class': 'rainfall'}).text.split()[2].split('mm')[0]\" \n",
    "        self._soup_inst_dict[\"p_rainfall\"] = \"global p_rainfall; p_rainfall = None; \" \\\n",
    "                                   \"p_rainfall = soup.find('div', \" \\\n",
    "                                   \"{'class': 'info_list rainfall _tabContent'}).text.strip().split()[2][:-1]\" \n",
    "        self._soup_inst_dict[\"wind_speed\"] = \"global wind_speed; wind_speed = None; \" \\\n",
    "                                   \"wind_speed = soup.find('div', \" \\\n",
    "                                   \"{'class': 'info_list wind _tabContent'}).text.strip().split()[2][:-3]\"\n",
    "        self._soup_inst_dict[\"humidity\"] = \"global humidity; humidity = None; \" \\\n",
    "                                   \"humidity = soup.find('div', \" \\\n",
    "                                   \"{'class': 'info_list humidity _tabContent'}).text.strip().split()[2][:-1]\"\n",
    "        \n",
    "        \n",
    "    def main(self):\n",
    "        self._information_crawler()\n",
    "    \n",
    "    \n",
    "    def _information_crawler(self):\n",
    "        self._read_url()\n",
    "        self._information_crawling()\n",
    "    \n",
    "    \n",
    "    def _read_url(self):\n",
    "        def _check_information_file_validation(_info):\n",
    "            if len(_info) == 0:\n",
    "                print(\"URL information file is empty. Please check.\")\n",
    "                sys.exit(0)\n",
    "            _valid_count = 0\n",
    "            for url in _info:\n",
    "                value = url.strip().split(\"@\")[1]\n",
    "                if len(value) != 0:\n",
    "                    _valid_count += 1\n",
    "            if _valid_count == 0 :\n",
    "                print(\"There is no url in the file. Please check.\")\n",
    "                sys.exit(0)\n",
    "         \n",
    "        try:\n",
    "            _url_file =  open('./url_information.txt', 'rt', encoding='utf8')\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"The file containing url information doesn't exist in the same path. Please check.\")\n",
    "            sys.exit(0)\n",
    "        _url_information = _url_file.readlines()\n",
    "        _check_information_file_validation(_url_information)\n",
    "        self._set_url_dict(_url_information)\n",
    "        \n",
    "        \n",
    "    def _information_crawling(self):\n",
    "        def _filter_none_information(instruction, soup):\n",
    "            try:\n",
    "                exec(instruction)\n",
    "            except Exception:\n",
    "                raise AttributeError\n",
    "                    \n",
    "            \n",
    "        url_dict = self._url_dict   \n",
    "        _crawled_value_dict = {}\n",
    "        for key, value in url_dict.items():\n",
    "            url = url_dict[key]\n",
    "            html = requests.get(url)\n",
    "            plain_text = html.text   \n",
    "            soup = bs(plain_text, 'lxml')\n",
    "            self._set__soup_inst_dict()\n",
    "            area = soup.find('span', {'class': 'btn_select'}).find('em').text\n",
    "            for name, inst in self._soup_inst_dict.items():\n",
    "                try:\n",
    "                    _filter_none_information(inst, soup)\n",
    "                except AttributeError as e:\n",
    "                    print(f\"{name} information of {area} is none.\")\n",
    "                    _crawled_value_dict[name] = None\n",
    "                else:\n",
    "                    _crawled_value_dict[name] = eval(name) \n",
    "            _crawled_value_dict[\"uv_num\"], _crawled_value_dict[\"uv_non_num_content\"] = \\\n",
    "                                                    self._get_uv_information(area, soup)\n",
    "            for key, value in self._get_dust_and_ozone_information(area, soup).items():\n",
    "                _crawled_value_dict[key] = value\n",
    "            \n",
    " \n",
    "    def _get_uv_information(self, region, soup):\n",
    "        try:\n",
    "            _uv_content = soup.find('span', {'class': 'indicator'}).find('span').text\n",
    "        except AttributeError:\n",
    "            print(f\"UV information of {region} is none.\")\n",
    "            return (None, None)\n",
    "        try:\n",
    "            _uv_num = soup.find('span', {'class': 'indicator'}).find('span', {'class': \"num\"}).text\n",
    "        except AttributeError:\n",
    "            print(f\"UV number information of {region} is none.\")\n",
    "            return (None, None)\n",
    "        _uv_non_num_content_point = _uv_content.find(_uv_num)+len(_uv_num)\n",
    "        _uv_non_num_content = _uv_content[_uv_non_num_content_point: ]\n",
    "        return (_uv_num, _uv_non_num_content)\n",
    "    \n",
    "    \n",
    "    def _get_dust_and_ozone_information(self, region, soup):\n",
    "        _fine_dust = None\n",
    "        _fine_dust_num = None\n",
    "        _ultra_fine_dust = None\n",
    "        _ultra_fine_dust_num = None\n",
    "        _ozone = None\n",
    "        _ozone_num = None\n",
    "        _dust_list = []\n",
    "        _ozone_text = \"\"\n",
    "        for ele in soup.find_all('dd'):\n",
    "            if \"㎍/㎥\" in ele.text:\n",
    "                _dust_list.append(ele.text)\n",
    "            elif \"ppm\" in ele.text:\n",
    "                _ozone_text = ele.text\n",
    "        try:\n",
    "            if 'null' not in _dust_list[0].split(\"㎍/㎥\"):\n",
    "                _fine_dust = _dust_list[0].split(\"㎍/㎥\")[1]\n",
    "                _fine_dust_num = _dust_list[0].split(\"㎍/㎥\")[0]\n",
    "            else:\n",
    "                print(f\"Some fine dust information of {region} are missing.\")\n",
    "        except IndexError:\n",
    "            print(f\"All fine dust information of {region} are none.\")\n",
    "           \n",
    "        try:\n",
    "            if 'null' not in _dust_list[1].split(\"㎍/㎥\"):\n",
    "                _ultra_fine_dust = _dust_list[1].split(\"㎍/㎥\")[1]\n",
    "                _ultra_fine_dust_num = _dust_list[1].split(\"㎍/㎥\")[0]\n",
    "            else:\n",
    "                print(f\"Some ultra fine dust information of {region} are missing.\")\n",
    "        except IndexError:\n",
    "            print(f\"Ultra fine dust information of {region} are none.\")\n",
    "            \n",
    "        if _ozone_text is not '':\n",
    "            _ozone = _ozone_text.split(\"ppm\")[1]\n",
    "            _ozone_num = _ozone_text.split(\"ppm\")[0]\n",
    "        else:\n",
    "            print(f\"Ozone information of {region} is none.\")\n",
    "        _value_dict = {}\n",
    "        _value_dict['fine_dust'] = _fine_dust \n",
    "        _value_dict['fine_dust_num'] = _fine_dust_num \n",
    "        _value_dict['ultra_fine_dust'] = _ultra_fine_dust \n",
    "        _value_dict['ultra_fine_dust_num'] = _ultra_fine_dust_num \n",
    "        _value_dict['ozone'] = _ozone \n",
    "        _value_dict['ozone_num'] = _ozone_num\n",
    "        return _value_dict\n",
    "            \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    weather_info = WeatherInformationCralwer()\n",
    "    weather_info.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"\"\n",
    "\"\".split(\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
